#!/bin/bash
set -e
echo "Setting up local environment for Weather Data Pipeline"
echo ""

ENV_FILE=".env"
SNOWFLAKE_WAREHOUSE=WEATHER_WH
SNOWFLAKE_DATABASE=WEATHER_ANALYTICS
SNOWFLAKE_ROLE=ACCOUNTADMIN
SNOWFLAKE_SCHEMA=BRONZE
# Helper function to ask for input
ask() {
  local var_name=$1
  local prompt=$2
  local secret=${3:-false}

  if [ "$secret" = true ]; then
    read -s -p "$prompt: " value
    echo ""
  else
    read -p "$prompt: " value
  fi

  if [ -z "$value" ]; then
    echo "âŒ $var_name cannot be empty"
    exit 1
  fi

  echo "$var_name=$value" >> "$ENV_FILE"
  export "$var_name=$value"
}

# Backup existing .env
if [ -f "$ENV_FILE" ]; then
  cp "$ENV_FILE" "$ENV_FILE.bak.$(date +%s)"
  echo "ðŸ“¦ Existing .env backed up"
fi

# Start fresh
echo "# Auto-generated by setup.sh" > "$ENV_FILE"

echo "Snowflake configuration"
echo ""
echo "You can query in your Snowflake web the following SQL using your ACCOUNTADMIN role please"
echo "SELECT CURRENT_ACCOUNT(), CURRENT_USER(), CURRENT_REGION(), CURRENT_ROLE();"
echo ""
echo ""
ask "SNOWFLAKE_ACCOUNT"   "Snowflake account (example: YS80657.us-east-2.aws)"
ask "SNOWFLAKE_USER"      "Snowflake user"
ask "SNOWFLAKE_PASSWORD"  "Snowflake password" true

echo "SNOWFLAKE_WAREHOUSE=$SNOWFLAKE_WAREHOUSE" >> .env
echo "SNOWFLAKE_DATABASE=$SNOWFLAKE_DATABASE" >> .env
echo "SNOWFLAKE_ROLE=$SNOWFLAKE_ROLE" >> .env
echo "SNOWFLAKE_SCHEMA=$SNOWFLAKE_SCHEMA" >> .env

echo ""
echo "" >> .env
echo "Setting up your Airflow / Postgres configuration"
echo "POSTGRES_USER=airflow" >> .env
echo "POSTGRES_PASSWORD=airflow" >> .env
echo "POSTGRES_DB=airflow" >> .env

# aibyte
echo "AIRBYTE_API_URL=http://host.docker.internal:8000/api/v1" >> .env

# important for Kubernetes/ Databricks
#ask "AIRFLOW_FERNET_KEY" "Airflow Fernet key (generate if you don't have one)"
echo "AIRFLOW_FERNET_KEY=not_key" >> .env

echo ""
PROJECT_ROOT_DIRECTORY="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
echo "PROJECT_ROOT=$PROJECT_ROOT_DIRECTORY" >> .env


# Postgres weather (CDC + incremental reads)
echo "WEATHER_PG_HOST=local-postgres" >> .env
echo "WEATHER_PG_PORT=5432" >> .env
echo "WEATHER_PG_DB=weather_prod" >> .env
echo "WEATHER_PG_USER=weather_user" >> .env
echo "WEATHER_PG_PASSWORD=weather_password" >> .env

echo ""
echo ".env file successfully created!"

DBT_DIR="dbt"
DBT_PROFILES_FILE="$DBT_DIR/profiles.yml"

cat > "$DBT_PROFILES_FILE" <<EOF
weather_pipeline:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: $SNOWFLAKE_ACCOUNT
      user: $SNOWFLAKE_USER
      password: $SNOWFLAKE_PASSWORD
      role: $SNOWFLAKE_ROLE
      warehouse: $SNOWFLAKE_WAREHOUSE
      database: $SNOWFLAKE_DATABASE
      schema: BRONZE
      threads: 4
EOF

echo "dbt profile created at dbt/profiles.yml"

echo ""
echo "Now we'll create the Snowflake Remote environment using Terraform"

echo "Installing snowflake-snowsql"
brew install --cask snowflake-snowsql

echo "setting up a user "
echo "Type your Snowflake ACCOUNTADMIN password "
snowsql -a $SNOWFLAKE_ACCOUNT \
        -u $SNOWFLAKE_USER \
        -r ACCOUNTADMIN \
        -w $SNOWFLAKE_WAREHOUSE \
        -d $SNOWFLAKE_DATABASE \
        -f "./infra/remote/snowflake/setup/roles.sql" \
        -s BRONZE \
        -o log_level=DEBUG

echo ""
echo "User: TERRAFORM_USER"
echo "Password: STRONG_P@SSW0RD123"
echo "Role: TERRAFORM_ROLE"

echo "Switching Terraform authentication to TERRAFORM_USER"

SNOWFLAKE_ACCOUNT_FULL="$SNOWFLAKE_ACCOUNT"
IFS='-' read -r SNOWFLAKE_COMPANY SNOWFLAKE_ACCOUNT <<< "$SNOWFLAKE_ACCOUNT_FULL"

export TF_VAR_snowflake_account_name="$SNOWFLAKE_ACCOUNT"
export TF_VAR_snowflake_organization_name="$SNOWFLAKE_COMPANY"
export TF_VAR_snowflake_region="AWS_SA_EAST_1"
#export TF_VAR_snowflake_user="TERRAFORM_USER"
export TF_VAR_snowflake_user="$SNOWFLAKE_USER"
#export TF_VAR_snowflake_password="STRONG_P@SSW0RD123"
export TF_VAR_snowflake_password="$SNOWFLAKE_PASSWORD"
#export TF_VAR_snowflake_role="TERRAFORM_ROLE"
export TF_VAR_snowflake_role="ACCOUNTADMIN"

echo "Creating snowflake remote environment"

cd ./infra/remote/snowflake

terraform init

# Import warehouse if not already managed
if ! terraform state show snowflake_warehouse.weather_wh >/dev/null 2>&1; then
  echo "Importing warehouse WEATHER_WH"
  terraform import snowflake_warehouse.weather_wh WEATHER_WH
  terraform import snowflake_database.weather_analytics WEATHER_ANALYTICS
  terraform import snowflake_schema.bronze "WEATHER_ANALYTICS.BRONZE"
  terraform import snowflake_schema.silver "WEATHER_ANALYTICS.SILVER"
  terraform import snowflake_schema.gold   "WEATHER_ANALYTICS.GOLD"

else
  echo "Warehouse WEATHER_WH already managed by Terraform"
fi

terraform plan

terraform apply -auto-approve

echo ""

echo "Project is ready to run locally!!!"
echo "Running ./infra/local/start_containers.sh"
cd $PROJECT_ROOT_DIRECTORY/infra/local

chmod +x start_containers.sh
./start_containers.sh

echo ""
echo ""
echo "Login in airflow using account: admin password: admin"
sleep 20
open http://localhost:8081/home
