version: "3.8"

services:
  postgres-airflow:
    image: postgres:13
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow

    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5
    restart: always

  airflow-init:
    build:
      context: ${PROJECT_ROOT}
      dockerfile: infra/local/airflow/Dockerfile
    env_file:
      - ${PROJECT_ROOT}/.env
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
    command: >
      bash -c "
      airflow db migrate && airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com && chmod +x /opt/airflow/init_connections.sh && /opt/airflow/init_connections.sh;
      "
    volumes:
      - ${PROJECT_ROOT}/infra/local/airflow/init_connections.sh:/opt/airflow/init_connections.sh

  airflow-webserver:
    env_file:
      - ${PROJECT_ROOT}/.env
    build:
      context: ${PROJECT_ROOT}
      dockerfile: infra/local/airflow/Dockerfile
    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__FERNET_KEY: ""
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: "true"
    volumes:
      - ${PROJECT_ROOT}/airflow/dags:/opt/airflow/dags
      - ${PROJECT_ROOT}/src:/opt/airflow/dags/src
      - ${PROJECT_ROOT}/dbt:/opt/airflow/dbt
      - airflow-logs:/opt/airflow/logs

    ports:
      - "8081:8080"
    restart: always
    command: >
      bash -c "
      python -m pip install --upgrade pip &&
      python -m pip install dbt-core dbt-snowflake &&
      airflow webserver
      "

  airflow-scheduler:
    env_file:
      - ${PROJECT_ROOT}/.env
    build:
      context: ${PROJECT_ROOT}
      dockerfile: infra/local/airflow/Dockerfile
    command: >
      bash -c "
      python -m pip install --upgrade pip &&
      python -m pip install dbt-core dbt-snowflake &&
      airflow scheduler
      "

    depends_on:
      postgres-airflow:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres-airflow/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "false"
      AIRFLOW__CORE__FERNET_KEY: ""
    volumes:
      - ${PROJECT_ROOT}/airflow/dags:/opt/airflow/dags
      - ${PROJECT_ROOT}/src:/opt/airflow/dags/src
      - airflow-logs:/opt/airflow/logs
      - ${PROJECT_ROOT}/dbt:/opt/airflow/dbt
      - ${PROJECT_ROOT}/infra/local/airflow/validation:/opt/airflow/validation
    restart: always

volumes:
  postgres-db-volume:
  airflow-logs:
  validation:
